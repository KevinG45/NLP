{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682889cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1d9ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb223d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a6751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n"
     ]
    }
   ],
   "source": [
    "#Q1. Try using the Python interpreter as a calculator, and typing expressions like 12 / (4 + 1).\n",
    "result = 12 / (4 + 1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1865c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142930641582938830174357788501626427282669988762475256374173175398995908420104023465432599069702289330964075081611719197835869803511992549376\n"
     ]
    }
   ],
   "source": [
    "#Q2.Given an alphabet of 26 letters, there are 26 to the power 10, or 26 ** 10, ten-letter strings we can form. That works out to 141167095653376. \n",
    "# How many hundred-letter strings are possible?\n",
    "print(26**100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dafa757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'curator', 'of', 'the', 'louvre', 'jacques', 'saunière', 'staggered', 'through', 'the', 'vaulted', 'archway', 'of', 'the', 'museum', 's', 'grand', 'gallery', 'he', 'clutched', 'his', 'chest', 'his', 'fingers', 'smeared', 'with', 'blood', 'beneath', 'the', 'eerie', 'glow', 'of', 'the', 'gallery', 'lights', 'priceless', 'paintings', 'gazed', 'down', 'with', 'eternal', 'stillness', 'somewhere', 'behind', 'him', 'footsteps', 'echoed', 'panic', 'surged', 'saunière', 'turned', 'slipping', 'on', 'the', 'polished', 'floor', 'as', 'he', 'fell', 'memories', 'flooded', 'his', 'symbols', 'secret', 'societies', 'hidden', 'truths', 'buried', 'in', 'history', 'he', 'knew', 'his', 'time', 'was', 'short', 'in', 'trembling', 'strokes', 'he', 'wrote', 'a', 'last', 'clue']\n",
      "['a', 'archway', 'as', 'behind', 'beneath', 'blood', 'buried', 'chest', 'clue', 'clutched', 'curator', 'down', 'echoed', 'eerie', 'eternal', 'fell', 'fingers', 'flooded', 'floor', 'footsteps', 'gallery', 'gallery', 'gazed', 'glow', 'grand', 'he', 'he', 'he', 'he', 'hidden', 'him', 'his', 'his', 'his', 'his', 'history', 'in', 'in', 'jacques', 'knew', 'last', 'lights', 'louvre', 'memories', 'museum', 'of', 'of', 'of', 'on', 'paintings', 'panic', 'polished', 'priceless', 's', 'saunière', 'saunière', 'secret', 'short', 'slipping', 'smeared', 'societies', 'somewhere', 'staggered', 'stillness', 'strokes', 'surged', 'symbols', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'through', 'time', 'trembling', 'truths', 'turned', 'vaulted', 'was', 'with', 'with', 'wrote']\n",
      "Total words: 84\n",
      "Unique words: 66\n",
      "Most frequent word: ('the', 7)\n",
      "Least frequent word: ('clue', 1)\n",
      "Longest word: staggered\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 2:Text Processing (Basics)\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# a)Define a string containing a paragraph as the value.\n",
    "paragraph = \"\"\"\n",
    "The curator of the Louvre, Jacques Saunière, staggered through the vaulted archway of the museum’s Grand Gallery. \n",
    "He clutched his chest, his fingers smeared with blood. Beneath the eerie glow of the gallery lights, priceless \n",
    "paintings gazed down with eternal stillness. Somewhere behind him, footsteps echoed. Panic surged. Saunière \n",
    "turned, slipping on the polished floor. As he fell, memories flooded his mind—cryptic symbols, secret societies, \n",
    "hidden truths buried in history. He knew his time was short. In trembling strokes, he wrote a message—his last clue.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 1: Tokenize\n",
    "tokens = word_tokenize(paragraph)\n",
    "\n",
    "# Step 2: Normalize - lowercase and remove punctuation\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "print(words)\n",
    "sorted_words = sorted(words)\n",
    "print(sorted_words)\n",
    "#b)Write a program to print the number of total words and total unique words in the paragraph.\n",
    "# Step 3: Count total and unique words\n",
    "total_words = len(words)\n",
    "unique_words = len(set(words))\n",
    "\n",
    "\n",
    "#c)Find the frequency of all words and also display the most and least frequent word.\n",
    "# Step 4: Frequency\n",
    "freq = Counter(words)\n",
    "\n",
    "# Step 5: Most and least frequent words\n",
    "most_freq = freq.most_common(1)[0]\n",
    "least_freq = freq.most_common()[-1]\n",
    "\n",
    "\n",
    "#d)Find the longest word in the paragraph.\n",
    "# Step 6: Longest word\n",
    "longest_word = max(words, key=len)\n",
    "\n",
    "# Step 7: Output\n",
    "print(f\"Total words: {total_words}\")\n",
    "print(f\"Unique words: {unique_words}\")\n",
    "print(f\"Most frequent word: {most_freq}\")\n",
    "print(f\"Least frequent word: {least_freq}\")\n",
    "print(f\"Longest word: {longest_word}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76108fd",
   "metadata": {},
   "source": [
    "Q3.Regular Expression<BR>\n",
    "2.1 Write regular expressions for the following languages: You may use either Perl<BR>\n",
    "notation or the minimal \"algebraic\" notation of Sec. 2.3, but make sure to say which<BR>\n",
    "one you are using. By \"word\", we mean an alphabetic string separated from other<BR>\n",
    "words by white space, any relevant punctuation, line breaks, and so forth.<BR>\n",
    "a. the set of all alphabetic strings.<BR>\n",
    "b. the set of all lowercase alphabetic strings ending in a b.<BR>\n",
    "c. the set of all strings with two consecutive repeated words (e.g., \"Humbert Hum-\n",
    "bert\" and \"the the\" but not \"the bug%r \"the big bug\").<BR>\n",
    "d. the set of all strings from the alphabet a, b such that each a is immediately pre-<BR>\n",
    "ceded and immediately followed by a b.<BR>\n",
    "e. all strings which startat the beginning of the line with an integer (i.e., 10,<BR>\n",
    "...,10000,...)<BR>\n",
    "and which end at the end of the line with a word.<BR>\n",
    "f. all strings which have both the word grotto and the word raven in them. (but not,<BR>\n",
    "for example, words like grottos that merely contain the word grotto).<BR>\n",
    "g. write a pattern which places the first word of an English sentence in a register.<BR>\n",
    "Deal with punctuation.<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2.1 Regular Expression Tester\n",
      "\n",
      "# a. All alphabetic strings\n",
      "  'Hello' -> Match\n",
      "  'world' -> Match\n",
      "  '123' -> No match\n",
      "  'hello123' -> No match\n",
      "  'hello_world' -> No match\n",
      "\n",
      "------------------------------------------------------------\n",
      "# b. Lowercase alphabetic strings ending in 'b'\n",
      "  'b' -> Match\n",
      "  'ab' -> Match\n",
      "  'aab' -> Match\n",
      "  'abc' -> No match\n",
      "  'BB' -> No match\n",
      "  'bbb' -> Match\n",
      "\n",
      "------------------------------------------------------------\n",
      "# c. Two consecutive repeated words\n",
      "  'Humbert Humbert' -> Match\n",
      "  'the the' -> Match\n",
      "  'the bug' -> No match\n",
      "  'a a' -> Match\n",
      "  'yes no' -> No match\n",
      "\n",
      "------------------------------------------------------------\n",
      "# d. Strings from {a, b} where each 'a' is surrounded by 'b'\n",
      "  'bab' -> Match\n",
      "  'bbabb' -> Match\n",
      "  'ab' -> Match\n",
      "  'a' -> No match\n",
      "  'ba' -> No match\n",
      "  'abba' -> No match\n",
      "  'bbabbbab' -> Match\n",
      "\n",
      "------------------------------------------------------------\n",
      "# f. Start with integer and end with a word\n",
      "  '1000 hello' -> Match\n",
      "  '3 days remain' -> Match\n",
      "  '1' -> No match\n",
      "  'start 100' -> No match\n",
      "  '99 bottles' -> Match\n",
      "\n",
      "------------------------------------------------------------\n",
      "# g. Strings with both 'grotto' and 'raven'\n",
      "  'The raven found the grotto.' -> Match\n",
      "  'grotto and raven' -> Match\n",
      "  'grottos and ravens' -> No match\n",
      "  'raven in the cave' -> No match\n",
      "  'just a grotto' -> No match\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "print(\"\\n Regular Expression Tester\\n\")\n",
    "\n",
    "# a. the set of all alphabetic strings.\n",
    "regex_a = r'^[A-Za-z]+$'\n",
    "test_cases_a = [\"Hello\", \"world\", \"123\", \"hello123\", \"hello_world\"]\n",
    "print(\"# a. All alphabetic strings\")\n",
    "for test in test_cases_a:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.fullmatch(regex_a, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# b. the set of all lowercase alphabetic strings ending in a b.\n",
    "regex_b = r'^[a-z]*b$'\n",
    "test_cases_b = [\"b\", \"ab\", \"aab\", \"abc\", \"BB\", \"bbb\"]\n",
    "print(\"# b. Lowercase alphabetic strings ending in 'b'\")\n",
    "for test in test_cases_b:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.fullmatch(regex_b, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# c. Strings with two consecutive repeated words\n",
    "regex_c = r'\\b(\\w+)\\s+\\1\\b'\n",
    "test_cases_c = [\"Humbert Humbert\", \"the the\", \"the bug\", \"a a\", \"yes no\"]\n",
    "print(\"# c. Two consecutive repeated words\")\n",
    "for test in test_cases_c:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.search(regex_c, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# d. Strings from {a, b} where each 'a' is surrounded by 'b'\n",
    "regex_d = r'^(b*ab+)*b*$'\n",
    "test_cases_d = [\"bab\", \"bbabb\", \"ab\", \"a\", \"ba\", \"abba\", \"bbabbbab\"]\n",
    "print(\"# d. Strings from {a, b} where each 'a' is surrounded by 'b'\")\n",
    "for test in test_cases_d:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.fullmatch(regex_d, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# f. Strings that start with an integer and end with a word\n",
    "regex_f = r'^\\d+.*\\b([A-Za-z]+)\\b$'\n",
    "test_cases_f = [\"1000 hello\", \"3 days remain\", \"1\", \"start 100\", \"99 bottles\"]\n",
    "print(\"# f. Start with integer and end with a word\")\n",
    "for test in test_cases_f:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.match(regex_f, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# g. Strings with both \"grotto\" and \"raven\"\n",
    "regex_g = r'\\b(grotto)\\b.*\\b(raven)\\b|\\b(raven)\\b.*\\b(grotto)\\b'\n",
    "test_cases_g = [\"The raven found the grotto.\", \"grotto and raven\", \"grottos and ravens\", \"raven in the cave\", \"just a grotto\"]\n",
    "print(\"# g. Strings with both 'grotto' and 'raven'\")\n",
    "for test in test_cases_g:\n",
    "    print(f\"  {test!r} ->\", \"Match\" if re.search(regex_g, test) else \"No match\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2890370",
   "metadata": {},
   "source": [
    "Q.3\n",
    "2.2 Implement an ELIZA-Iike program, using substitutions such as those described<BR>\n",
    "on page IO. You may choose a different domain than a Rogerian psychologist, if you<BR>\n",
    "wish, although keep in mind that you would need a domain in which your program can<BR>\n",
    "legitimately do a lot of simple repeating-back.<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb285a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIZA: Hello, I'm your virtual therapist. How can I help you today?\n",
      "ELIZA: Would it really help you to get help?\n",
      "ELIZA: How long have you been tired?\n",
      "ELIZA: Perhaps eventually I will listen.\n",
      "ELIZA: Why do you say that your friends ignore you?\n",
      "ELIZA: Can you elaborate on that?\n",
      "ELIZA: Can you elaborate on that?\n",
      "ELIZA: How does that make you feel?\n",
      "ELIZA: Please tell me more.\n",
      "ELIZA: Let's change focus a bit… Tell me about your family.\n",
      "ELIZA: Please tell me more.\n",
      "ELIZA: Why do you say that no?\n",
      "ELIZA: Why do you say that no?\n",
      "ELIZA: Why do you say that yes?\n",
      "ELIZA: Please tell me more.\n",
      "ELIZA: Can you elaborate on that?\n",
      "ELIZA: Can you elaborate on that?\n",
      "ELIZA: Please tell me more.\n",
      "ELIZA: Why do you say that breathe?\n",
      "ELIZA: Goodbye! Take care.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# Reflection dictionary for pronoun changes\n",
    "reflections = {\n",
    "    \"i am\": \"you are\",\n",
    "    \"i was\": \"you were\",\n",
    "    \"i\": \"you\",\n",
    "    \"my\": \"your\",\n",
    "    \"me\": \"you\",\n",
    "    \"am\": \"are\",\n",
    "    \"you are\": \"I am\",\n",
    "    \"you're\": \"I'm\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"you\": \"I\"\n",
    "}\n",
    "\n",
    "# Basic substitution rules (pattern, response)\n",
    "patterns = [\n",
    "    (r'I need (.*)',\n",
    "     [\"Why do you need {0}?\",\n",
    "      \"Would it really help you to get {0}?\",\n",
    "      \"Are you sure you need {0}?\"]),\n",
    "\n",
    "    (r'Why don\\'?t you ([^\\?]*)\\??',\n",
    "     [\"Do you really think I don't {0}?\",\n",
    "      \"Perhaps eventually I will {0}.\",\n",
    "      \"Do you really want me to {0}?\"]),\n",
    "\n",
    "    (r'I can\\'?t (.*)',\n",
    "     [\"How do you know you can't {0}?\",\n",
    "      \"Perhaps you could {0} if you tried.\",\n",
    "      \"What would it take for you to {0}?\"]),\n",
    "\n",
    "    (r'I am (.*)',\n",
    "     [\"Did you come to me because you are {0}?\",\n",
    "      \"How long have you been {0}?\",\n",
    "      \"How do you feel about being {0}?\"]),\n",
    "\n",
    "    (r'(.*)\\?',\n",
    "     [\"Why do you ask that?\",\n",
    "      \"What do you think?\",\n",
    "      \"Can you answer your own question?\"]),\n",
    "\n",
    "    (r'(.*)',\n",
    "     [\"Please tell me more.\",\n",
    "      \"Let's change focus a bit… Tell me about your family.\",\n",
    "      \"Can you elaborate on that?\",\n",
    "      \"How does that make you feel?\",\n",
    "      \"Why do you say that {0}?\"])\n",
    "]\n",
    "\n",
    "# Function to substitute reflections\n",
    "def reflect(fragment):\n",
    "    words = fragment.lower().split()\n",
    "    reflected = [reflections.get(word, word) for word in words]\n",
    "    return ' '.join(reflected)\n",
    "\n",
    "# ELIZA main response generator\n",
    "def eliza_response(user_input):\n",
    "    for pattern, responses in patterns:\n",
    "        match = re.match(pattern, user_input, re.IGNORECASE)\n",
    "        if match:\n",
    "            groups = match.groups()\n",
    "            reflected_groups = [reflect(g) for g in groups]\n",
    "            response = random.choice(responses)\n",
    "            return response.format(*reflected_groups)\n",
    "    return \"I'm not sure I understand you.\"\n",
    "\n",
    "# Chat loop\n",
    "print(\"ELIZA: Hello, I'm your virtual therapist. How can I help you today?\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"ELIZA: Goodbye! Take care.\")\n",
    "        break\n",
    "    response = eliza_response(user_input)\n",
    "    print(\"ELIZA:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
